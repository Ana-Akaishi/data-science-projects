{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning & Increasing model penalization\n",
    "\n",
    "For this notebook, I'll use the adjusted set from feature engineering notebook on Logit, XGBoost, Light GBM, SVM and Neural Network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import merged dataset (train + test)\n",
    "default_df = pd.read_csv('default_df.csv')\n",
    "\n",
    "# Separate between features (X) and answer (y)\n",
    "x = default_df.drop(['Unnamed: 0','Loan Status'], axis=1)\n",
    "y = default_df['Loan Status']\n",
    "\n",
    "# Split dataset considering train and test must have default class\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.72383308,  1.86829987, -1.12465675, ..., -0.07329356,\n",
       "        -0.26825135,  1.132089  ],\n",
       "       [-0.21837308, -1.48909439,  2.60800807, ..., -0.07329356,\n",
       "        -0.26825135, -0.88332278],\n",
       "       [ 0.39358773, -0.8656642 ,  1.4718614 , ..., -0.07329356,\n",
       "        -0.26825135,  1.132089  ],\n",
       "       ...,\n",
       "       [ 0.37456118,  0.50831164,  0.74053434, ..., -0.07329356,\n",
       "        -0.26825135, -0.88332278],\n",
       "       [ 1.41037126,  0.8771428 , -0.8366547 , ..., -0.07329356,\n",
       "        -0.26825135,  1.132089  ],\n",
       "       [ 1.77462794,  0.62045791, -0.30038245, ..., -0.07329356,\n",
       "        -0.26825135, -0.88332278]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a standard scaler based on train set\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Use train set as reference\n",
    "scaler.fit_transform(x_train)\n",
    "\n",
    "# Transform test without contaminating it\n",
    "scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documentos\\My_Py_Projects\\github_DS_projects\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Create instance for Logit model\n",
    "logit = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# Fit model in my training set\n",
    "logit.fit(x_train, y_train)\n",
    "\n",
    "# Predict y_test\n",
    "logit_predict = logit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      " [[12479 13658]\n",
      " [  780   996]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.48      0.63     26137\n",
      "         1.0       0.07      0.56      0.12      1776\n",
      "\n",
      "    accuracy                           0.48     27913\n",
      "   macro avg       0.50      0.52      0.38     27913\n",
      "weighted avg       0.89      0.48      0.60     27913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "logit_matrix = metrics.confusion_matrix(y_test, logit_predict)\n",
    "print('Confusion Matrix','\\n',logit_matrix, '\\n')\n",
    "\n",
    "print(metrics.classification_report(y_test, logit_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.63</td>\n",
       "      <td>26137.00</td>\n",
       "      <td>logit IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1776.00</td>\n",
       "      <td>logit IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>logit IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.38</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>logit IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.60</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>logit IP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score   support     Model\n",
       "0.0                0.94    0.48      0.63  26137.00  logit IP\n",
       "1.0                0.07    0.56      0.12   1776.00  logit IP\n",
       "accuracy           0.48    0.48      0.48      0.48  logit IP\n",
       "macro avg          0.50    0.52      0.38  27913.00  logit IP\n",
       "weighted avg       0.89    0.48      0.60  27913.00  logit IP"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract classification report\n",
    "class_report2 = metrics.classification_report(y_test, logit_predict, output_dict=True)\n",
    "class_report2 = pd.DataFrame(class_report2).round(2).transpose()\n",
    "class_report2['Model'] = 'logit IP'\n",
    "class_report2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the positive class weight\n",
    "pos_class_weight = (len(y) - np.sum(y)) / np.sum(y)\n",
    "\n",
    "# Create XGBoost instance\n",
    "XGB = xgb.XGBClassifier(scale_pos_weight=pos_class_weight)\n",
    "\n",
    "# Fit he model\n",
    "XGB.fit(x_train, y_train)\n",
    "\n",
    "# Pedict\n",
    "xgb_predict = XGB.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix \n",
      " [[20886  5251]\n",
      " [ 1342   434]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.80      0.86     26137\n",
      "         1.0       0.08      0.24      0.12      1776\n",
      "\n",
      "    accuracy                           0.76     27913\n",
      "   macro avg       0.51      0.52      0.49     27913\n",
      "weighted avg       0.88      0.76      0.82     27913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analyze performance\n",
    "print('Confusion matrix', '\\n',metrics.confusion_matrix(y_test, xgb_predict), '\\n')\n",
    "\n",
    "print(metrics.classification_report(y_test, xgb_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary class report \n",
    "temp_class_report2 = metrics.classification_report(y_test, xgb_predict, output_dict=True)\n",
    "temp_class_report2 = pd.DataFrame(temp_class_report2).round(2).transpose()\n",
    "temp_class_report2['Model'] = 'xgb IP'\n",
    "\n",
    "# Concat with main df\n",
    "class_report2 = pd.concat([class_report2, temp_class_report2], axis=0)\n",
    "\n",
    "# Display final df\n",
    "# class_report2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4144, number of negative: 60985\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4144\n",
      "[LightGBM] [Info] Number of data points in the train set: 65129, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.063628 -> initscore=-2.688966\n",
      "[LightGBM] [Info] Start training from score -2.688966\n"
     ]
    }
   ],
   "source": [
    "# Create instance\n",
    "lgb = lgbm.LGBMClassifier(scale_pos_weight=pos_class_weight)\n",
    "\n",
    "# Fit in train set\n",
    "lgb.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "lgb_predict = lgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[16971  9166]\n",
      " [ 1051   725]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.65      0.77     26137\n",
      "         1.0       0.07      0.41      0.12      1776\n",
      "\n",
      "    accuracy                           0.63     27913\n",
      "   macro avg       0.51      0.53      0.45     27913\n",
      "weighted avg       0.89      0.63      0.73     27913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "print('Confusion Matrix:', '\\n',metrics.confusion_matrix(y_test,lgb_predict), '\\n')\n",
    "\n",
    "# Classification report\n",
    "print(metrics.classification_report(y_test, lgb_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary classification report df\n",
    "temp_class_report2 = metrics.classification_report(y_test, lgb_predict, output_dict=True)\n",
    "temp_class_report2 = pd.DataFrame(temp_class_report2).round(2).transpose()\n",
    "temp_class_report2['Model'] = 'Light GBM IP'\n",
    "\n",
    "# Concat with main report\n",
    "class_report2 = pd.concat([class_report2, temp_class_report2], axis=0)\n",
    "# class_report2\n",
    "class_report2.to_csv('classification_report2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictiornary with the ideal weight\n",
    "dw = {0: 1, 1: pos_class_weight}\n",
    "\n",
    "# Instance model\n",
    "svc = svm.SVC(class_weight=dw)\n",
    "\n",
    "# Fit\n",
    "svc.fit(x_train, y_train)\n",
    "\n",
    "# Predict\n",
    "svc_predict = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix \n",
      " [[10454 15683]\n",
      " [  627  1149]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.40      0.56     26137\n",
      "         1.0       0.07      0.65      0.12      1776\n",
      "\n",
      "    accuracy                           0.42     27913\n",
      "   macro avg       0.51      0.52      0.34     27913\n",
      "weighted avg       0.89      0.42      0.53     27913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See results\n",
    "print('Confusion matrix', '\\n', metrics.confusion_matrix(y_test, svc_predict))\n",
    "\n",
    "# Classification report\n",
    "print(metrics.classification_report(y_test, svc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary classification report\n",
    "temp_class_report2 = metrics.classification_report(y_test, svc_predict, output_dict=True)\n",
    "temp_class_report2 = pd.DataFrame(temp_class_report2).round(2).transpose()\n",
    "temp_class_report2['Model'] = 'SVM IP'\n",
    "\n",
    "# Merge with report df\n",
    "class_report2 = pd.concat([class_report2, temp_class_report2], axis=0)\n",
    "# class_report2\n",
    "class_report2.to_csv('classification_report2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65129, 36)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First transform df in arrays. This is the way tensorflow builds its models\n",
    "x_train_a = x_train.to_numpy()\n",
    "y_train_a = y_train.to_numpy()\n",
    "x_test_a = x_test.to_numpy()\n",
    "y_test_a = y_test.to_numpy()\n",
    "\n",
    "x_train_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documentos\\My_Py_Projects\\github_DS_projects\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build neural netwrok\n",
    "ann_sgd = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(64, input_shape=(36,), activation='tanh'),\n",
    "  tf.keras.layers.Dense(32, activation='tanh'),\n",
    "  tf.keras.layers.Dropout(0.20),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.5207 - loss: 1.3374\n",
      "Epoch 2/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4865 - loss: 1.3119\n",
      "Epoch 3/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4508 - loss: 1.3123\n",
      "Epoch 4/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5345 - loss: 1.2872\n",
      "Epoch 5/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4943 - loss: 1.2999\n",
      "Epoch 6/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6374 - loss: 1.2843\n",
      "Epoch 7/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5147 - loss: 1.2950\n",
      "Epoch 8/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3659 - loss: 1.3113\n",
      "Epoch 9/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4784 - loss: 1.3054\n",
      "Epoch 10/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4634 - loss: 1.3073\n",
      "Epoch 11/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4711 - loss: 1.3030\n",
      "Epoch 12/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6029 - loss: 1.2829\n",
      "Epoch 13/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5602 - loss: 1.2954\n",
      "Epoch 14/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5354 - loss: 1.2837\n",
      "Epoch 15/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5104 - loss: 1.2949\n",
      "Epoch 16/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5221 - loss: 1.2875\n",
      "Epoch 17/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3971 - loss: 1.3104\n",
      "Epoch 18/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5983 - loss: 1.2925\n",
      "Epoch 19/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3973 - loss: 1.3051\n",
      "Epoch 20/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4208 - loss: 1.3096\n",
      "Epoch 21/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4807 - loss: 1.2911\n",
      "Epoch 22/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5298 - loss: 1.3011\n",
      "Epoch 23/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5849 - loss: 1.2897\n",
      "Epoch 24/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4399 - loss: 1.3001\n",
      "Epoch 25/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4885 - loss: 1.2919\n",
      "Epoch 26/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4602 - loss: 1.3051\n",
      "Epoch 27/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4050 - loss: 1.3014\n",
      "Epoch 28/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5669 - loss: 1.2866\n",
      "Epoch 29/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4628 - loss: 1.3031\n",
      "Epoch 30/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5308 - loss: 1.2966\n",
      "Epoch 31/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5554 - loss: 1.2975\n",
      "Epoch 32/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5630 - loss: 1.2991\n",
      "Epoch 33/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5743 - loss: 1.2891\n",
      "Epoch 34/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4618 - loss: 1.3019\n",
      "Epoch 35/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5798 - loss: 1.3024\n",
      "Epoch 36/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4717 - loss: 1.3016\n",
      "Epoch 37/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4774 - loss: 1.2984\n",
      "Epoch 38/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3744 - loss: 1.2999\n",
      "Epoch 39/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4140 - loss: 1.3002\n",
      "Epoch 40/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4585 - loss: 1.3078\n",
      "Epoch 41/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5929 - loss: 1.2827\n",
      "Epoch 42/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6061 - loss: 1.2900\n",
      "Epoch 43/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4101 - loss: 1.2939\n",
      "Epoch 44/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5780 - loss: 1.2959\n",
      "Epoch 45/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5688 - loss: 1.2880\n",
      "Epoch 46/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3272 - loss: 1.3070\n",
      "Epoch 47/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3207 - loss: 1.3100\n",
      "Epoch 48/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3966 - loss: 1.3177\n",
      "Epoch 49/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5546 - loss: 1.2951\n",
      "Epoch 50/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4670 - loss: 1.2972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23d80f5d390>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and fit\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "# Since this is a classification problem, our loss analysis also changes from MSE to binarycrossentropy\n",
    "ann_sgd.compile(optimizer=opt, \n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Predic\n",
    "ann_sgd.fit(x_train_a, y_train_a, class_weight={0: 1.0, 1: pos_class_weight}, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 866us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict using ANN, and here I'll round rthe predictions so we have 1 (defualt) and 0 (non-default) instead of float numbers\n",
    "ann_sgd_predict = (ann_sgd.predict(x_test_a) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix \n",
      " [[25909   228]\n",
      " [ 1765    11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96     26137\n",
      "         1.0       0.05      0.01      0.01      1776\n",
      "\n",
      "    accuracy                           0.93     27913\n",
      "   macro avg       0.49      0.50      0.49     27913\n",
      "weighted avg       0.88      0.93      0.90     27913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See results\n",
    "print('Confusion matrix', '\\n', metrics.confusion_matrix(y_test_a, ann_sgd_predict))\n",
    "\n",
    "# Classification report\n",
    "print(metrics.classification_report(y_test_a, ann_sgd_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary classification report\n",
    "temp_class_report2 = metrics.classification_report(y_test_a, ann_sgd_predict, output_dict=True)\n",
    "temp_class_report2 = pd.DataFrame(temp_class_report2).round(2).transpose()\n",
    "temp_class_report2['Model'] = 'ANN SGD IP'\n",
    "\n",
    "# Merge with report df\n",
    "class_report2 = pd.concat([class_report2, temp_class_report2], axis=0)\n",
    "\n",
    "# Save\n",
    "class_report2.to_csv('classification_report2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documentos\\My_Py_Projects\\github_DS_projects\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.4678 - loss: 1.3397\n",
      "Epoch 2/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5522 - loss: 1.2952\n",
      "Epoch 3/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5600 - loss: 1.2954\n",
      "Epoch 4/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4660 - loss: 1.3110\n",
      "Epoch 5/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4500 - loss: 1.3187\n",
      "Epoch 6/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5112 - loss: 1.3143\n",
      "Epoch 7/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5180 - loss: 1.2974\n",
      "Epoch 8/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4860 - loss: 1.2977\n",
      "Epoch 9/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5093 - loss: 1.2962\n",
      "Epoch 10/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5363 - loss: 1.2927\n",
      "Epoch 11/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4632 - loss: 1.3298\n",
      "Epoch 12/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4565 - loss: 1.3070\n",
      "Epoch 13/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5355 - loss: 1.3061\n",
      "Epoch 14/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5193 - loss: 1.3036\n",
      "Epoch 15/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4529 - loss: 1.3157\n",
      "Epoch 16/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5671 - loss: 1.2980\n",
      "Epoch 17/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4689 - loss: 1.3148\n",
      "Epoch 18/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5188 - loss: 1.3060\n",
      "Epoch 19/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4674 - loss: 1.3156\n",
      "Epoch 20/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5119 - loss: 1.3025\n",
      "Epoch 21/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4927 - loss: 1.3177\n",
      "Epoch 22/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5364 - loss: 1.2993\n",
      "Epoch 23/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5256 - loss: 1.3025\n",
      "Epoch 24/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5160 - loss: 1.3009\n",
      "Epoch 25/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4771 - loss: 1.3066\n",
      "Epoch 26/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5520 - loss: 1.2993\n",
      "Epoch 27/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4186 - loss: 1.3207\n",
      "Epoch 28/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5436 - loss: 1.3013\n",
      "Epoch 29/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4493 - loss: 1.3090\n",
      "Epoch 30/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5646 - loss: 1.2919\n",
      "Epoch 31/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4729 - loss: 1.3179\n",
      "Epoch 32/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5361 - loss: 1.2993\n",
      "Epoch 33/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5331 - loss: 1.2968\n",
      "Epoch 34/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5281 - loss: 1.3048\n",
      "Epoch 35/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5152 - loss: 1.3000\n",
      "Epoch 36/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4560 - loss: 1.3131\n",
      "Epoch 37/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5088 - loss: 1.3160\n",
      "Epoch 38/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4779 - loss: 1.3103\n",
      "Epoch 39/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5252 - loss: 1.2889\n",
      "Epoch 40/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4403 - loss: 1.3292\n",
      "Epoch 41/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4989 - loss: 1.3109\n",
      "Epoch 42/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4333 - loss: 1.3192\n",
      "Epoch 43/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4899 - loss: 1.3036\n",
      "Epoch 44/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5686 - loss: 1.2889\n",
      "Epoch 45/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5598 - loss: 1.2962\n",
      "Epoch 46/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4723 - loss: 1.3107\n",
      "Epoch 47/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4972 - loss: 1.3110\n",
      "Epoch 48/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4879 - loss: 1.3095\n",
      "Epoch 49/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4763 - loss: 1.3195\n",
      "Epoch 50/50\n",
      "\u001b[1m2036/2036\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4587 - loss: 1.3190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23da1dc8050>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using similar architecture\n",
    "ann_adam = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(64, input_shape=(36,), activation='relu'),\n",
    "  tf.keras.layers.Dense(32, activation='tanh'),\n",
    "  tf.keras.layers.Dropout(0.20),\n",
    "  tf.keras.layers.Dense(10, activation='tanh'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile and fit\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Since this is a classification problem, our loss analysis also changes from MSE to binarycrossentropy\n",
    "ann_adam.compile(optimizer=opt, \n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Fit in train sets\n",
    "ann_adam.fit(x_train_a, y_train_a, class_weight={0: 1.0, 1: pos_class_weight}, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m873/873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict using ANN, and here I'll round rthe predictions so we have 1 (defualt) and 0 (non-default) instead of float numbers\n",
    "ann_adam_predict = (ann_adam.predict(x_test_a) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix \n",
      " [[    0 26137]\n",
      " [    0  1776]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     26137\n",
      "         1.0       0.06      1.00      0.12      1776\n",
      "\n",
      "    accuracy                           0.06     27913\n",
      "   macro avg       0.03      0.50      0.06     27913\n",
      "weighted avg       0.00      0.06      0.01     27913\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documentos\\My_Py_Projects\\github_DS_projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Documentos\\My_Py_Projects\\github_DS_projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Documentos\\My_Py_Projects\\github_DS_projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# See results\n",
    "print('Confusion matrix', '\\n', metrics.confusion_matrix(y_test_a, ann_adam_predict))\n",
    "\n",
    "# Classification report\n",
    "print(metrics.classification_report(y_test_a, ann_adam_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documentos\\My_Py_Projects\\github_DS_projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Documentos\\My_Py_Projects\\github_DS_projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\Documentos\\My_Py_Projects\\github_DS_projects\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.63</td>\n",
       "      <td>26137.00</td>\n",
       "      <td>logit IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1776.00</td>\n",
       "      <td>logit IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>logit IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.38</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>logit IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.60</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>logit IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>26137.00</td>\n",
       "      <td>xgb IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1776.00</td>\n",
       "      <td>xgb IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>xgb IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>xgb IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>xgb IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.77</td>\n",
       "      <td>26137.00</td>\n",
       "      <td>Light GBM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1776.00</td>\n",
       "      <td>Light GBM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>Light GBM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.45</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>Light GBM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.73</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>Light GBM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.56</td>\n",
       "      <td>26137.00</td>\n",
       "      <td>SVM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1776.00</td>\n",
       "      <td>SVM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>SVM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.34</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>SVM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.53</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>SVM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>26137.00</td>\n",
       "      <td>ANN SGD IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1776.00</td>\n",
       "      <td>ANN SGD IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>ANN SGD IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>ANN SGD IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>ANN SGD IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26137.00</td>\n",
       "      <td>ANN ADAM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.06</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1776.00</td>\n",
       "      <td>ANN ADAM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>ANN ADAM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.06</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>ANN ADAM IP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>27913.00</td>\n",
       "      <td>ANN ADAM IP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score   support         Model\n",
       "0.0                0.94    0.48      0.63  26137.00      logit IP\n",
       "1.0                0.07    0.56      0.12   1776.00      logit IP\n",
       "accuracy           0.48    0.48      0.48      0.48      logit IP\n",
       "macro avg          0.50    0.52      0.38  27913.00      logit IP\n",
       "weighted avg       0.89    0.48      0.60  27913.00      logit IP\n",
       "0.0                0.94    0.80      0.86  26137.00        xgb IP\n",
       "1.0                0.08    0.24      0.12   1776.00        xgb IP\n",
       "accuracy           0.76    0.76      0.76      0.76        xgb IP\n",
       "macro avg          0.51    0.52      0.49  27913.00        xgb IP\n",
       "weighted avg       0.88    0.76      0.82  27913.00        xgb IP\n",
       "0.0                0.94    0.65      0.77  26137.00  Light GBM IP\n",
       "1.0                0.07    0.41      0.12   1776.00  Light GBM IP\n",
       "accuracy           0.63    0.63      0.63      0.63  Light GBM IP\n",
       "macro avg          0.51    0.53      0.45  27913.00  Light GBM IP\n",
       "weighted avg       0.89    0.63      0.73  27913.00  Light GBM IP\n",
       "0.0                0.94    0.40      0.56  26137.00        SVM IP\n",
       "1.0                0.07    0.65      0.12   1776.00        SVM IP\n",
       "accuracy           0.42    0.42      0.42      0.42        SVM IP\n",
       "macro avg          0.51    0.52      0.34  27913.00        SVM IP\n",
       "weighted avg       0.89    0.42      0.53  27913.00        SVM IP\n",
       "0.0                0.94    0.99      0.96  26137.00    ANN SGD IP\n",
       "1.0                0.05    0.01      0.01   1776.00    ANN SGD IP\n",
       "accuracy           0.93    0.93      0.93      0.93    ANN SGD IP\n",
       "macro avg          0.49    0.50      0.49  27913.00    ANN SGD IP\n",
       "weighted avg       0.88    0.93      0.90  27913.00    ANN SGD IP\n",
       "0.0                0.00    0.00      0.00  26137.00   ANN ADAM IP\n",
       "1.0                0.06    1.00      0.12   1776.00   ANN ADAM IP\n",
       "accuracy           0.06    0.06      0.06      0.06   ANN ADAM IP\n",
       "macro avg          0.03    0.50      0.06  27913.00   ANN ADAM IP\n",
       "weighted avg       0.00    0.06      0.01  27913.00   ANN ADAM IP"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temporary classification report\n",
    "temp_class_report2 = metrics.classification_report(y_test_a, ann_adam_predict, output_dict=True)\n",
    "temp_class_report2 = pd.DataFrame(temp_class_report2).round(2).transpose()\n",
    "temp_class_report2['Model'] = 'ANN ADAM IP'\n",
    "\n",
    "# Merge with report df\n",
    "class_report2 = pd.concat([class_report2, temp_class_report2], axis=0)\n",
    "\n",
    "# Save\n",
    "class_report2.to_csv('classification_report2.csv')\n",
    "\n",
    "# Display final results\n",
    "class_report2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
