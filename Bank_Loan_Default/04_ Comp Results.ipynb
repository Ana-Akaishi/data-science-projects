{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Results: Synthetic data vs Increse Model Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I tested the same models with two different techniques to handle imbalance, let's see which one performed better.\n",
    "\n",
    "- Synthetic data for minority class: `classification_report.csv`\n",
    "- Increase Penalty for positive class (minority): `classification_report2.csv`\n",
    "\n",
    "\n",
    "## Concerns\n",
    "Since EDA, I noticed train and test sets aren't similar and have very different behavior on their clients and their features related to risk. For instance, grade A clients have the same interest rate as risky grades (which doesn't make much sense specially when the loan value is similar).\n",
    "\n",
    "For this, I have couple of hypothesis for why is it happening:\n",
    "1. We are missing other important information when it comes to risk analysis: age, location, investment account, ocuppation.\n",
    "2. Train set with suspect data: in my EDA test set have the expected risk x rate relation we would expect in these sorts of scenarios. But **train set** doesn't seems to understand this relationship. And one explenation for it not reflect the real world is because train set data is synthetic generated by some algorithm like K-means.\n",
    "\n",
    "Since my dataset is not balanced, accuracy might be an unrealiable metric to look. I'll focus on macro avg, since it considers the proportion of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results sets\n",
    "synt = pd.read_csv('classification_report.csv')\n",
    "ip = pd.read_csv('classification_report2.csv')\n",
    "\n",
    "# Concat sets into one\n",
    "results = pd.concat([synt,ip], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  precision  recall  f1-score   support     Model\n",
      "0             0       0.91    0.57      0.70  17463.00     logit\n",
      "1             1       0.09    0.44      0.16   1776.00     logit\n",
      "2      accuracy       0.56    0.56      0.56      0.56     logit\n",
      "3     macro avg       0.50    0.51      0.43  19239.00     logit\n",
      "4  weighted avg       0.83    0.56      0.65  19239.00     logit\n",
      "0             0       0.91    0.52      0.66  17463.00  logit IP\n",
      "1             1       0.10    0.50      0.16   1776.00  logit IP\n",
      "2      accuracy       0.51    0.51      0.51      0.51  logit IP\n",
      "3     macro avg       0.50    0.51      0.41  19239.00  logit IP\n",
      "4  weighted avg       0.84    0.51      0.61  19239.00  logit IP\n"
     ]
    }
   ],
   "source": [
    "print(results[results['Model'].str.contains('logit')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideting the **macro avg** **f1-score** , the models are not so different in terms of performance. While Logistical Regression with synthetic data was 0.02 point better, both models are far from identifying default clients (the ideal would be f1 = 1 or closer to)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  precision  recall  f1-score   support   Model\n",
      "5             0       0.91    1.00      0.95  17463.00     xgb\n",
      "6             1       0.11    0.00      0.01   1776.00     xgb\n",
      "7      accuracy       0.90    0.90      0.90      0.90     xgb\n",
      "8     macro avg       0.51    0.50      0.48  19239.00     xgb\n",
      "9  weighted avg       0.83    0.90      0.86  19239.00     xgb\n",
      "5             0       0.91    0.85      0.88  17463.00  xgb IP\n",
      "6             1       0.09    0.15      0.11   1776.00  xgb IP\n",
      "7      accuracy       0.78    0.78      0.78      0.78  xgb IP\n",
      "8     macro avg       0.50    0.50      0.50  19239.00  xgb IP\n",
      "9  weighted avg       0.83    0.78      0.81  19239.00  xgb IP\n"
     ]
    }
   ],
   "source": [
    "print(results[results['Model'].str.contains('xgb')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between XGBoosts, increase penalty was 0.01 point better than synthetic data. Compared to **Logit with Synthetic data** (macro avg f1: 0.43), **XGBoost IP** (macro avg f1: 0.50) had better results, and was able to classify both classes (default = 1, and non-default = 0) better than previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  precision  recall  f1-score   support         Model\n",
      "10             0       0.91    1.00      0.95  17463.00     Light GBM\n",
      "11             1       0.25    0.00      0.00   1776.00     Light GBM\n",
      "12      accuracy       0.91    0.91      0.91      0.91     Light GBM\n",
      "13     macro avg       0.58    0.50      0.48  19239.00     Light GBM\n",
      "14  weighted avg       0.85    0.91      0.86  19239.00     Light GBM\n",
      "10             0       0.91    0.75      0.82  17463.00  Light GBM IP\n",
      "11             1       0.10    0.27      0.15   1776.00  Light GBM IP\n",
      "12      accuracy       0.71    0.71      0.71      0.71  Light GBM IP\n",
      "13     macro avg       0.50    0.51      0.48  19239.00  Light GBM IP\n",
      "14  weighted avg       0.84    0.71      0.76  19239.00  Light GBM IP\n"
     ]
    }
   ],
   "source": [
    "print(results[results['Model'].str.lower().str.contains('light')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While XGBoost and **Light GBM** have a similar use of gradients on their algorithms, their techniques differ and we see the impact on the results. **Light GBM** will focus on maximizing the leaf in each decision tree. This allows to get the minimum error per branch, but has a high chance of overfitting.\n",
    "\n",
    "Between the both imbalance techniques, both had the same results (macro avg f1: 0.48) and it's very close to **XGBoost IP** (macro avg f1: 0.50)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  precision  recall  f1-score   support   Model\n",
      "15             0       0.91    0.36      0.51  17463.00     SVM\n",
      "16             1       0.09    0.64      0.16   1776.00     SVM\n",
      "17      accuracy       0.38    0.38      0.38      0.38     SVM\n",
      "18     macro avg       0.50    0.50      0.34  19239.00     SVM\n",
      "19  weighted avg       0.83    0.38      0.48  19239.00     SVM\n",
      "15             0       0.91    0.64      0.75  17463.00  SVM IP\n",
      "16             1       0.10    0.38      0.15   1776.00  SVM IP\n",
      "17      accuracy       0.61    0.61      0.61      0.61  SVM IP\n",
      "18     macro avg       0.50    0.51      0.45  19239.00  SVM IP\n",
      "19  weighted avg       0.83    0.61      0.70  19239.00  SVM IP\n"
     ]
    }
   ],
   "source": [
    "print(results[results['Model'].str.lower().str.contains('svm')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was hoping that non-linearity would be the answer for a better model, but seems I was wrong. Non-linearity doesn't seems to be better than a simple linear regression (Logit).\n",
    "\n",
    "Our winning model still **XGBoost IP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifical Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  precision  recall  f1-score   support       Model\n",
      "20             0       0.90    0.02      0.04  17463.00     ANN SGD\n",
      "21             1       0.09    0.98      0.17   1776.00     ANN SGD\n",
      "22      accuracy       0.11    0.11      0.11      0.11     ANN SGD\n",
      "23     macro avg       0.49    0.50      0.11  19239.00     ANN SGD\n",
      "24  weighted avg       0.82    0.11      0.05  19239.00     ANN SGD\n",
      "20             0       0.91    0.00      0.01  17463.00  ANN SGD IP\n",
      "21             1       0.09    1.00      0.17   1776.00  ANN SGD IP\n",
      "22      accuracy       0.09    0.09      0.09      0.09  ANN SGD IP\n",
      "23     macro avg       0.50    0.50      0.09  19239.00  ANN SGD IP\n",
      "24  weighted avg       0.84    0.09      0.02  19239.00  ANN SGD IP \n",
      "\n",
      "     Unnamed: 0  precision  recall  f1-score   support   Model\n",
      "5             0       0.91    0.85      0.88  17463.00  xgb IP\n",
      "6             1       0.09    0.15      0.11   1776.00  xgb IP\n",
      "7      accuracy       0.78    0.78      0.78      0.78  xgb IP\n",
      "8     macro avg       0.50    0.50      0.50  19239.00  xgb IP\n",
      "9  weighted avg       0.83    0.78      0.81  19239.00  xgb IP\n"
     ]
    }
   ],
   "source": [
    "print(results[results['Model'].str.lower().str.contains('sgd')], '\\n')\n",
    "print(results[results['Model'].str.lower().str.contains('xgb ip')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a **ANN SGD** didn't perform well. We can see f1-scores were under 0.50, and we read this as the model has trouble classifying default clients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  precision  recall  f1-score   support        Model\n",
      "25             0       0.91    1.00      0.95  17463.00     ANN ADAM\n",
      "26             1       0.00    0.00      0.00   1776.00     ANN ADAM\n",
      "27      accuracy       0.91    0.91      0.91      0.91     ANN ADAM\n",
      "28     macro avg       0.45    0.50      0.48  19239.00     ANN ADAM\n",
      "29  weighted avg       0.82    0.91      0.86  19239.00     ANN ADAM\n",
      "25             0       0.91    1.00      0.95  17463.00  ANN ADAM IP\n",
      "26             1       0.00    0.00      0.00   1776.00  ANN ADAM IP\n",
      "27      accuracy       0.91    0.91      0.91      0.91  ANN ADAM IP\n",
      "28     macro avg       0.45    0.50      0.48  19239.00  ANN ADAM IP\n",
      "29  weighted avg       0.82    0.91      0.86  19239.00  ANN ADAM IP \n",
      "\n",
      "     Unnamed: 0  precision  recall  f1-score   support   Model\n",
      "5             0       0.91    0.85      0.88  17463.00  xgb IP\n",
      "6             1       0.09    0.15      0.11   1776.00  xgb IP\n",
      "7      accuracy       0.78    0.78      0.78      0.78  xgb IP\n",
      "8     macro avg       0.50    0.50      0.50  19239.00  xgb IP\n",
      "9  weighted avg       0.83    0.78      0.81  19239.00  xgb IP\n"
     ]
    }
   ],
   "source": [
    "print(results[results['Model'].str.lower().str.contains('adam')], '\\n')\n",
    "print(results[results['Model'].str.lower().str.contains('xgb ip')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANN Adam** performed a little better (macro avg f1-score: 0.48) regardless the imbalanced method used.\n",
    "\n",
    "Both models also got close to XGBoost results (macro avg f1-score: 0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take aways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I tested different models using two different techniques to deal with imbalanced dataset. In general, SMOT or increase model penalty will have different effects depending on the model. For this dataset, seems like increasing penalty had a better effect on XGBoost model than synthetic data.\n",
    "\n",
    "Another interestinng thing is the result of the models itself. While it was quite difficult to find a good model, the **XGBoost IP** (macro avg f1: 0.50) presented the best option to predict default clients even with all the differences and weird behavior I found on EDA. It is important to notice that even though the model display the best result between the models, **default clients** are still hard to predict.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
