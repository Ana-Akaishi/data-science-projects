{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFF Machine Learning\n",
    "In this notebook, I'll test some machine learning (ML) algorithms on Brazilian Financial Funds. The inspiration is to create an algorithm able to forecast funds return so investor can plan and adjust their strategy.\n",
    "\n",
    "THIS IS NOT A FINANCIAL ADVISE, just an experiment to test different ML algorithms and see which one perform better. It is also possible that none will be good, which is fine! This will give enthusiasts insight to keep looking for more variables that may influence funds return.\n",
    "\n",
    "I'll test the following algorithms:\n",
    "- Linear Regression\n",
    "- Non-linear Regression: \n",
    "    1. Support Vector Machine (SVM)\n",
    "    2. XGBoost\n",
    "- Neural Networks:\n",
    "    1. Artificial Neural Networks (ANN)\n",
    "    2. Recursive Neural Networks (RNN)\n",
    "    3. Long Short Term Memory (LSTM) - *a type of RNN*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepping data\n",
    "Before I start modeling, I need to make sure my data fits the requeriments of my algorithms. Since I'm dealing with different data scales (monetary, rates, dummy), my models will have a hard time adjusting to it all.\n",
    "\n",
    "To fix that, I'll use StandardScaler from sklearn to adjust my values based on the standard deviation. This will make sure we have a similar scale to compare my features and will be easier to models to process.\n",
    "\n",
    "Since my models will use a train, validation and test sets, it's important not influenec the test dataset. So first, I'll:\n",
    "1. Drops the rows with issues identified on my 'Cleaning Datasets' phase: all data with error on register data\n",
    "2. Split my dataset in 3: train, validation and test\n",
    "3. Create a scaler for training and valdiation: later, I'll use the **same** scaler on test set\n",
    "4. Run my models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import financial fund df\n",
    "fund_df = pd.read_csv('fund_df.csv')\n",
    "\n",
    "fund_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observations with issue on register\n",
    "print(f'Fund DF complete: ', fund_df.shape)\n",
    "fund_df = fund_df.drop(fund_df['correct_name'] == False)\n",
    "fund_df = fund_df.drop(columns=['DENOM_SOCIAL', 'DT_REG', 'manager_name', 'isuer_name', 'big4_name'], axis=1)\n",
    "\n",
    "# Check the final shape after drops\n",
    "print(f'Fund DF after drop: ', fund_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split fund df into test, validation and test\n",
    "## Split features (X) and independent variable (y)\n",
    "X = fund_df.drop('quota_return', axis=1)\n",
    "y = fund_df['quota_return']\n",
    "\n",
    "# Create subsets for traininn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# Nor subset for validation and test. I'm setting it to 50% so we have an even split between validation and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform X_train\n",
    "scaler.fit_transform(X_train)\n",
    "\n",
    "# Only transform y_train, X_val, y_val\n",
    "scaler.transform(y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "First, let's try a classic linear regression. I'm trying to predict quota's return (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance for linear regression model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Fit the model in my training sets (X and y)\n",
    "lm.fit(X_train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
